import time
import json
import re
import pandas as pd
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.edge.service import Service as EdgeService
from selenium.webdriver.edge.options import Options as EdgeOptions
from selenium.webdriver.common.by import By
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.microsoft import EdgeChromiumDriverManager
from unidecode import unidecode
# Configuration
GROUP_URL = "https://www.facebook.com/groups/656390831772336"
MAX_SCROLL_ATTEMPTS = 5
SCROLL_WAIT_TIME = 2
COMMENT_LOAD_WAIT = 4

index  = 0
# Initialisation du navigateur Edge
options = EdgeOptions()
options.add_argument("--start-maximized")
options.add_argument("--disable-notifications")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_experimental_option("excludeSwitches", ["enable-automation"])
driver_path = "C:\\Users\\papid\\Downloads\\edgedriver_win64\\msedgedriver.exe"  
driver = webdriver.Edge(service=EdgeService(executable_path=driver_path), options=options)

data = pd.read_csv("postes.csv")

def load_cookies():
    """Charger et injecter les cookies Facebook"""
    try:
        driver.get("https://web.facebook.com")
        time.sleep(3)
        
        with open("facebook_cookies.json", "r", encoding="utf-8") as file:
            cookies = json.load(file)
        
        print(f"üìÅ {len(cookies)} cookies charg√©s depuis le fichier")
        
        for cookie in cookies:
            # Nettoyer les attributs non support√©s
            for key in ["sameSite", "storeId", "id", "hostOnly", "session"]:
                cookie.pop(key, None)
            try:
                driver.add_cookie(cookie)
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur avec le cookie {cookie.get('name', 'inconnu')}: {e}")
        
        print("‚úÖ Cookies inject√©s avec succ√®s")
        return True
        
    except FileNotFoundError:
        print("‚ùå Fichier facebook_cookies.json non trouv√©!")
        return False
    except Exception as e:
        print(f"‚ùå Erreur lors du chargement des cookies: {e}")
        return False

def verify_login():
    """V√©rifier si l'utilisateur est connect√©"""
    try:
        # Chercher des √©l√©ments indiquant qu'on n'est pas connect√©
        login_indicators = [
            "//input[@name='email']",
            "//input[@name='pass']",
            "//a[contains(text(), 'Se connecter')]",
            "//button[contains(text(), 'Se connecter')]"
        ]
        
        for indicator in login_indicators:
            if driver.find_elements(By.XPATH, indicator):
                return False
        
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de la v√©rification de connexion: {e}")
        return False

def wait_for_facebook_page_loaded(timeout=60):
    """Attendre que la page Facebook soit compl√®tement charg√©e"""
    print("üîÑ Attente du chargement de la page Facebook...")
    
    # 1. Attendre que le document soit pr√™t
    try:
        WebDriverWait(driver, timeout).until(
            lambda d: d.execute_script("return document.readyState") == "complete"
        )
        print("‚úÖ Document ready")
    except TimeoutException:
        print("‚ö†Ô∏è Timeout document ready")
    
    # 2. Attendre les √©l√©ments principaux Facebook
    main_selectors = [
        "[role='main']",
        "[data-pagelet]",
        "div[id^='mount_']",
        "div[data-ad-comet-preview='message']",
        "div[role='article']"
    ]
    
    element_found = False
    for selector in main_selectors:
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, selector))
            )
            print(f"‚úÖ √âl√©ment principal trouv√©: {selector}")
            element_found = True
            break
        except TimeoutException:
            continue
    
    if not element_found:
        print("‚ö†Ô∏è Aucun √©l√©ment principal trouv√©, continuons...")
    
    # 3. Attendre que les spinners/loaders disparaissent
    loader_selectors = [
        "[aria-label='Chargement...']",
        ".loading",
        ".spinner",
        "[role='progressbar']"
    ]
    
    for selector in loader_selectors:
        try:
            WebDriverWait(driver, 5).until(
                EC.invisibility_of_element_located((By.CSS_SELECTOR, selector))
            )
            print(f"‚úÖ Loader disparu: {selector}")
        except TimeoutException:
            continue
    
    # 4. Attendre stabilit√© du contenu
    try:
        wait_for_content_stability(
            selector="div[data-ad-comet-preview='message'], div[role='article']",
            timeout=20,
            stable_time=3
        )
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur stabilit√©: {e}")
    
    print("‚úÖ Page Facebook charg√©e!")
    return True

def wait_for_content_stability(selector, timeout=30, stable_time=3):
    """Attendre que le contenu soit stable"""
    print(f"üîÑ Attente de stabilit√© du contenu: {selector}")
    
    start_time = time.time()
    last_count = 0
    stable_start = None
    
    while time.time() - start_time < timeout:
        try:
            current_count = len(driver.find_elements(By.CSS_SELECTOR, selector))
            
            if current_count == last_count:
                if stable_start is None:
                    stable_start = time.time()
                elif time.time() - stable_start >= stable_time:
                    print(f"‚úÖ Contenu stable: {current_count} √©l√©ments")
                    return True
            else:
                stable_start = None
                last_count = current_count
                print(f"üìä √âl√©ments d√©tect√©s: {current_count}")
            
            time.sleep(1)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur v√©rification stabilit√©: {e}")
            time.sleep(1)
    
    print(f"‚ö†Ô∏è Timeout stabilit√© apr√®s {timeout}s")
    return False

def scroll_page_and_load_content():
    """Faire d√©filer la page pour charger plus de contenu"""
    print("üîÑ Scroll de la page pour charger le contenu...")
    data = []
    for i in range(MAX_SCROLL_ATTEMPTS):
        print(f"üìú Scroll {i+1}/{MAX_SCROLL_ATTEMPTS}")
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_WAIT_TIME)
        com = click_comment_buttons()
        data.extend(com)
    
    print("‚úÖ Scroll termin√©")

    # R√©cup√©ration des commentaires de tous les posts visibles
    # data = click_comment_buttons()
    return data



from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException



def click_comment_buttons():
    """Analyse les textes des posts, d√©tecte les mots-cl√©s, puis r√©cup√®re les commentaires"""
    print("üîÑ Analyse des posts et clic sur les boutons de commentaires...")

    comments_data = []
    posts = driver.find_elements(By.CSS_SELECTOR, "div[role='article']")
    print(f"üîç {len(posts)} posts trouv√©s")

    for i in range(len(posts)):
        try:
            print(f"üß© Traitement du post {i + 1}/{len(posts)}")

            # ‚ö†Ô∏è Recharger la liste des posts √† chaque boucle
            posts = driver.find_elements(By.CSS_SELECTOR, "div[role='article']")
            if i >= len(posts):
                break
            post = posts[i]

            # üîπ Cliquer sur "Voir plus" s‚Äôil est visible
            try:
                voir_plus = post.find_element(
                    By.XPATH,
                    ".//div[@role='button' and (contains(text(), 'Voir plus') or contains(text(), 'En voir plus'))]"
                )
                if voir_plus.is_displayed():
                    driver.execute_script("arguments[0].click();", voir_plus)
                    time.sleep(1)
                    print("üìå Bouton 'Voir plus' cliqu√©")
            except NoSuchElementException:
                pass
            except StaleElementReferenceException:
                print("‚ö†Ô∏è Bouton 'Voir plus' obsol√®te, on passe au suivant")
                continue

            # üîπ R√©cup√©ration du texte du post
            try:
                # R√©cup√®re tous les blocs story_message (courte + longue)
                text_blocks = [
                    e.text.strip()
                    for e in post.find_elements(By.CSS_SELECTOR, "div[data-ad-rendering-role='story_message']")
                    if e.text.strip()
                ]

                if not text_blocks:
                    print("‚ö†Ô∏è Aucun texte trouv√© pour ce post")
                    continue

                # Garde la version la plus longue (le texte complet)
                texte_post = max(text_blocks, key=len)
                print("üìù Texte du post r√©cup√©r√©.")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors de la r√©cup√©ration du texte : {e}")
                continue

            # üîπ Extraire la date et l‚Äôauteur
            try:
                date_element = post.find_element(
                    By.XPATH,
                    ".//a[contains(@href, '/posts/') and contains(@href, '?__cft__[0]=')]"
                )
                date_str = date_element.text.strip()
                formatte_date = convertir_date_facebook(date_str)

                nom_elem = post.find_element(By.CSS_SELECTOR, "div.xu06os2.x1ok221b")
                nom = nom_elem.text.strip().split("¬∑")[0].strip()
                print(f"üìÜ {formatte_date} - üë§ {nom}")
            except (NoSuchElementException, StaleElementReferenceException):
                formatte_date = None
                nom = "Auteur inconnu"

            # üîπ Nettoyage du texte du post
            post_text = unidecode(texte_post).lower()
            post_text = re.sub(r'[^\w\s]', '', post_text)
            post_text = re.sub(r'\s+', ' ', post_text)

            # üîπ V√©rification du mot-cl√©
            if not post_contient_mot_cle(post_text):
                print("‚õî Aucun mot-cl√© d√©tect√©, post ignor√©.")
                continue

            print("‚úÖ Mot-cl√© trouv√©, r√©cup√©ration des commentaires...")

            # üîπ Cliquer sur le bouton de commentaires
            try:
                comment_button = post.find_element(By.CSS_SELECTOR, "div[id^='_r_'][role='button']")
                driver.execute_script("arguments[0].click();", comment_button)
                time.sleep(2)
            except (NoSuchElementException, StaleElementReferenceException):
                print("‚ö†Ô∏è Bouton de commentaire introuvable ou obsol√®te")
                continue

            # üîπ Trouver le conteneur des commentaires
            container = find_comment_container()
            if not container:
                print("‚ùå Aucun container de commentaires trouv√©")
                continue

            # üîπ Extraire les commentaires
            commentaires = extract_comments(container)
            for c in commentaires:
                c["poste"] = post_text
                c["date_post"] = formatte_date
                c["auteur"] = nom

            comments_data.extend(commentaires)

            # üîπ Fermer le container de commentaires
            for c in driver.find_elements(By.CSS_SELECTOR, "div[aria-label='Fermer']"):
                try:
                    if c.is_displayed():
                        driver.execute_script("arguments[0].click();", c)
                        time.sleep(1)
                        print("‚úÖ Container ferm√©")
                        break
                except:
                    continue

        except StaleElementReferenceException:
            print(f"‚ö†Ô∏è Post {i} ignor√© (√©l√©ment obsol√®te)")
            continue
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sur le post {i}: {e}")
            continue

    return comments_data


def find_comment_container():
    """Trouver le container de commentaires avec diff√©rents s√©lecteurs"""
    print("üîç Recherche du container de commentaires...")
    
    container_selectors = [
        "div.html-div.x14z9mp.xat24cr.x1lziwak.xexx8yu.xyri2b.x18d9i69.x1c1uobl.x1gslohp",
    ]
    
    for selector in container_selectors:
        try:
            container = driver.find_element(By.CSS_SELECTOR, selector)
            print(f"‚úÖ Container trouv√© avec: {selector}")
            return container
        except NoSuchElementException:
            print(f"‚è≥ S√©lecteur non trouv√©: {selector}")
            continue
    
    print("‚ùå Aucun container de commentaires trouv√©")
    return None

def scroll_comment_container(container):
    """Faire d√©filer le container de commentaires jusqu'√† stabilit√©"""
    print("üîÑ Scroll du container de commentaires...")
    
    previous_children_count = 0

    
    while True:
        # Compter les enfants actuels
        current_children_count = len(container.find_elements(By.XPATH, "./*"))
        
        # Si le nombre d'enfants n'a pas chang√©, on sort
        if current_children_count == previous_children_count:
            print(f"‚úÖ Scroll termin√©. Nombre final d'enfants: {current_children_count}")
            break
        
        previous_children_count = current_children_count
        print(f"üìä Enfants trouv√©s: {current_children_count}")
        
        # Scroll vers le bas du container
        driver.execute_script("""
            var container = arguments[0];
            if (container.lastElementChild) {
                container.lastElementChild.scrollIntoView({ 
                    behavior: 'instant', 
                    block: 'end' 
                });
            }
        """, container)
        
        # Attendre que les nouveaux commentaires se chargent
        time.sleep(COMMENT_LOAD_WAIT)

def post_contient_mot_cle(post_text):
    """V√©rifie si le texte contient un mot-cl√© sensible"""
    mots_cles = ["sgci", "soci√©t√© g√©n√©rale", "la g√©n√©rale","sgbci","societe generale","la generale","#SGCI","#sgci","la general","#soci√©t√©G√©n√©rale"]
    post_text_lower = post_text
    return any(mot in post_text_lower for mot in mots_cles)



from datetime import datetime, timedelta
from selenium.webdriver.common.by import By

# Fonction pour convertir les dates relatives Facebook
import re
from datetime import datetime, timedelta
from selenium.webdriver.common.by import By

import re
from datetime import datetime, timedelta

import re
from datetime import datetime, timedelta
# from unidecode import unidecode

def convertir_date_facebook(date_str):
    """Convertit une date Facebook en format JJ-MM-AAAA"""
    aujourd_hui = datetime.today()
    date_str = date_str.lower().strip()

    # Mapping mois fran√ßais -> num√©ro
    mois = {
        "janvier":1, "f√©vrier":2, "fevrier":2, "mars":3, "avril":4, "mai":5, "juin":6,
        "juillet":7, "ao√ªt":8, "aout":8, "septembre":9, "octobre":10, "novembre":11, "d√©cembre":12, "decembre":12
    }

    try:
        if "min" in date_str:
            minutes = int(re.search(r"(\d+)", date_str).group(1))
            date_finale = aujourd_hui - timedelta(minutes=minutes)

        elif "h" in date_str :
            heures = int(re.search(r"(\d+)", date_str).group(1))
            date_finale = aujourd_hui - timedelta(hours=heures)

        elif "j" in date_str:
            jours = int(re.search(r"(\d+)", date_str).group(1))
            date_finale = aujourd_hui - timedelta(days=jours)

        elif "sem" in date_str:
            semaines = int(re.search(r"(\d+)", date_str).group(1))
            date_finale = aujourd_hui - timedelta(weeks=semaines)

        elif "ans" in date_str or "an" in date_str:
            annees = int(re.search(r"(\d+)", date_str).group(1))
            date_finale = aujourd_hui - timedelta(days=annees * 365)

        elif re.match(r"\d{1,2} \w+", date_str):
            # Nettoyer "√† HH:MM" si pr√©sent
            date_str = re.sub(r"\s*√†\s*\d{1,2}:\d{2}", "", date_str).strip()
            # S√©parer jour et mois
            parts = date_str.split()
            if len(parts) >= 2:
                jour = int(parts[0])
                mois_str = unidecode(parts[1])  # supprime les accents
                mois_num = mois.get(mois_str.lower(), None)
                if not mois_num:
                    return "Erreur de conversion"
                date_finale = datetime(aujourd_hui.year, mois_num, jour)
            else:
                return "Erreur de conversion"

        else:
            return "Format inconnu"

        return date_finale.strftime("%d-%m-%Y")

    except Exception:
        return "Erreur de conversion"


def extract_comments(container):
    """Extraction des commentaires Facebook avec auteur, texte, date"""
    print("üöÄ D√©but de l'extraction des commentaires...")
    data = []

    try:
        scroll_comment_container(container)

        # üëâ S√©lecteur de blocs complets de commentaire (parent de auteur + texte)
        full_comment_blocks = container.find_elements(By.XPATH, ".//div[contains(@class,'xv55zj0')]")
        print(f"‚úÖ {len(full_comment_blocks)} blocs de commentaires trouv√©s.")

        for i, block in enumerate(full_comment_blocks):
            try:
                # üîé Nom de l‚Äôauteur
                try:
                    author_element = block.find_element(By.XPATH, ".//a[.//span[@dir='auto']]")
                    author_name = author_element.text.strip()
                except:
                    author_name = "Auteur inconnu"

                # üîé Texte du commentaire
                try:
                    comment_element = block.find_element(By.XPATH, ".//div[@dir='auto']")
                    comment_text = comment_element.text.strip()
                except:
                    comment_text = ""

                if not comment_text or len(comment_text) <= 1:
                    continue

                # üîé Date
                try:
                    parent = block.find_element(By.XPATH, ".//ancestor::div[@role='article']")
                    date_element = parent.find_element(
                        By.XPATH,
                        ".//a[contains(@href, 'comment_id=') and (contains(@href, '/posts/') or contains(@href, '/videos/'))]"
                    )
                    raw_date = date_element.text.strip()
                    formatted_date = convertir_date_facebook(raw_date)
                except:
                    formatted_date = "Date non trouv√©e"

                # ‚úÖ Enregistrement
                data.append({
                    "date": formatted_date,
                    "auteur_com": author_name,
                    "source": "OLBCI",
                    "commentaire": comment_text
                })

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lors du traitement du bloc {i}: {e}")

        print(f"‚úÖ Total des commentaires extraits: {len(data)}")

    except Exception as e:
        print(f"‚ùå Erreur g√©n√©rale lors de l'extraction: {e}")

    return data


def main():
    """Fonction principale"""
    print("üöÄ D√©marrage du scraper Facebook...")
    
    try:
        # 1. Charger les cookies
        if not load_cookies():
            print("‚ùå Impossible de charger les cookies")
            return
        
        # 2. Acc√©der √† la page du groupe
        print(f"üîó Acc√®s au groupe: {GROUP_URL}")
        driver.get(GROUP_URL)
        
        # 3. V√©rifier la connexion
        if not verify_login():
            print("‚ùå Vous n'√™tes pas connect√©!")
            return
        
        print("‚úÖ Connexion v√©rifi√©e")
        
        # 4. Attendre le chargement complet
        wait_for_facebook_page_loaded()
        
        # 5. Scroll pour charger plus de contenu
        time.sleep(5)  # Petite pause pour √©viter les probl√®mes de chargement
        comments_data = scroll_page_and_load_content()
        
        # 6. Extraire les commentaires
      
        
        if not comments_data:
            print("‚ùå Aucun commentaire extrait")
            return
        
        # 7. Sauvegarder les donn√©es
        df = pd.DataFrame(comments_data)
        df =  df.drop_duplicates()
        df_concat = pd.concat([data, df], ignore_index=True).drop_duplicates()
        filename = "postes.csv"
        df_concat.to_csv(filename, index=False)
        
        print(f"‚úÖ Extraction termin√©e!")
        print(f"üìÅ Fichier sauvegard√©: {filename}")
        print(f"üìä Nombre de commentaires: {len(df_concat)}")
        
        # Afficher un aper√ßu

        print("\nüìù Aper√ßu des premiers commentaires:")
        for i, comment in enumerate(comments_data[:3]):
            print(f"{i+1}. {comment['commentaire'][:100]}...")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
    finally:
        print("üîö Fermeture du navigateur...")
        driver.quit()

if __name__ == "__main__":
    main()
